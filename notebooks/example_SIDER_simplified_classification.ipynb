{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIDER Side Effect Prediction with MACCS Fingerprints\n",
    "\n",
    "This notebook demonstrates a simplified approach to predicting drug side effects using the SIDER dataset.\n",
    "We'll use MACCS fingerprints (similar to the BACE example) and build classification models.\n",
    "\n",
    "**Key Differences from BACE:**\n",
    "- BACE: Regression (predict continuous pIC50 values)\n",
    "- SIDER: Multi-label classification (predict 27 different side-effect categories)\n",
    "\n",
    "For simplicity, we'll start by predicting a single side effect: 'Cardiac disorders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages (no DeepChem or TensorFlow needed - we'll use RDKit directly!)\n# This installs only what we need without TensorFlow dependencies\n!pip install rdkit scikit-learn xgboost pandas numpy matplotlib"
  },
  {
   "cell_type": "code",
   "source": "# Suppress warnings and ensure we don't accidentally import TensorFlow\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Explicitly set environment to avoid TensorFlow\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TF warnings if accidentally imported",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom rdkit import Chem\nfrom rdkit.Chem import Draw, MACCSkeys"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the SIDER Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SIDER dataset\n",
    "df = pd.read_csv('../data/raw/sider.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset shape\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Number of molecules: {df.shape[0]}\")\n",
    "print(f\"Number of side-effect categories: {df.shape[1] - 1}\")  # -1 for SMILES column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all side-effect categories\n",
    "side_effect_cols = [col for col in df.columns if col != 'smiles']\n",
    "print(\"\\nSide-effect categories:\")\n",
    "for i, col in enumerate(side_effect_cols, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution for 'Cardiac disorders'\n",
    "target_col = 'Cardiac disorders'\n",
    "print(f\"\\nClass distribution for '{target_col}':\")\n",
    "print(df[target_col].value_counts())\n",
    "print(f\"\\nPositive samples: {df[target_col].sum()} ({df[target_col].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Canonicalize SMILES\n",
    "\n",
    "Just like in the BACE example, we'll canonicalize SMILES to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize_smiles(smiles):\n",
    "    \"\"\"Convert non-canonical SMILES to canonical form.\n",
    "    \n",
    "    Args:\n",
    "        smiles: str, non-canonical SMILES of a molecule\n",
    "    \n",
    "    Returns:\n",
    "        canonical_smiles: str, canonical SMILES of the molecule\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            return None\n",
    "        canonical_smiles = Chem.MolToSmiles(mol)\n",
    "        return canonical_smiles\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Apply canonicalization\n",
    "df['canonical_smiles'] = df['smiles'].apply(canonicalize_smiles)\n",
    "\n",
    "# Remove any molecules that failed to canonicalize\n",
    "initial_count = len(df)\n",
    "df = df.dropna(subset=['canonical_smiles'])\n",
    "print(f\"Removed {initial_count - len(df)} invalid SMILES\")\n",
    "print(f\"Final dataset size: {len(df)} molecules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simplified dataframe for our task\n",
    "df_sider = df[['canonical_smiles', target_col]].copy()\n",
    "df_sider.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some molecules with and without cardiac disorders\n",
    "n = 6\n",
    "\n",
    "# Get 3 positive and 3 negative samples\n",
    "positive_samples = df_sider[df_sider[target_col] == 1].sample(min(3, df_sider[target_col].sum()))\n",
    "negative_samples = df_sider[df_sider[target_col] == 0].sample(3)\n",
    "df_sample = pd.concat([positive_samples, negative_samples])\n",
    "\n",
    "smiles = df_sample['canonical_smiles'].values\n",
    "labels = [f\"Cardiac: {val}\" for val in df_sample[target_col].values]\n",
    "molecs = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "\n",
    "Draw.MolsToGridImage(\n",
    "    molecs,\n",
    "    legends=labels,\n",
    "    subImgSize=(400, 300),\n",
    "    molsPerRow=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Generate MACCS Fingerprints\n\nWe'll use RDKit's MACCSkeys module directly (no need for DeepChem!)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate MACCS fingerprints using RDKit directly\ndef get_maccs_fingerprint(smiles):\n    \"\"\"\n    Generate MACCS keys fingerprint from a SMILES string.\n    \n    Args:\n        smiles: canonical SMILES string\n    \n    Returns:\n        numpy array of 167 binary values (0 or 1)\n    \"\"\"\n    try:\n        mol = Chem.MolFromSmiles(smiles)\n        if mol is None:\n            return np.zeros(167, dtype=int)\n        \n        # Generate MACCS fingerprint (167 bits)\n        maccs_fp = MACCSkeys.GenMACCSKeys(mol)\n        # Convert to numpy array\n        return np.array(maccs_fp, dtype=int)\n    except:\n        return np.zeros(167, dtype=int)\n\n# Apply to all molecules\nprint(\"Generating MACCS fingerprints for all molecules...\")\nmf_features = np.array([get_maccs_fingerprint(smiles) for smiles in df_sider['canonical_smiles']])\n\nprint(f\"MACCS fingerprint shape: {mf_features.shape}\")\nprint(f\"Number of features per molecule: {mf_features.shape[1]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any NaN values in features\n",
    "nan_count = np.isnan(mf_features).sum()\n",
    "print(f\"Total NaN values in features: {nan_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Selection: Remove Zero-Variance Features\n",
    "\n",
    "Just like in BACE, we'll remove features that have zero variance (all values are the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Remove zero-variance features\n",
    "selector = VarianceThreshold(threshold=0.0)\n",
    "mf_features_filtered = selector.fit_transform(mf_features)\n",
    "\n",
    "print(f\"Original number of features: {mf_features.shape[1]}\")\n",
    "print(f\"Number of features after removing zero-variance: {mf_features_filtered.shape[1]}\")\n",
    "print(f\"Removed {mf_features.shape[1] - mf_features_filtered.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mf_features_filtered\n",
    "y = df_sider[target_col]\n",
    "\n",
    "# 80/20 train-test split with fixed random seed\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest set class distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train Classification Models\n",
    "\n",
    "We'll train Random Forest and XGBoost classifiers (adapted from the BACE regression example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize models\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "xgb_clf = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def train_test_classifier(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    \"\"\"\n",
    "    Train a classification model and evaluate it.\n",
    "    \n",
    "    Args:\n",
    "        model: sklearn/xgboost classifier\n",
    "        X_train, y_train: training data\n",
    "        X_test, y_test: test data\n",
    "        model_name: name of the model for display\n",
    "    \"\"\"\n",
    "    # Train model\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Get probability predictions for ROC-AUC\n",
    "    y_pred_train_proba = model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    train_f1 = f1_score(y_train, y_pred_train)\n",
    "    test_f1 = f1_score(y_test, y_pred_test)\n",
    "    \n",
    "    train_roc_auc = roc_auc_score(y_train, y_pred_train_proba)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_pred_test_proba)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"  Train Accuracy: {train_acc:.3f} | Test Accuracy: {test_acc:.3f}\")\n",
    "    print(f\"  Train F1-Score: {train_f1:.3f} | Test F1-Score: {test_f1:.3f}\")\n",
    "    print(f\"  Train ROC-AUC:  {train_roc_auc:.3f} | Test ROC-AUC:  {test_roc_auc:.3f}\")\n",
    "    print()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Random Forest\n",
    "rf_clf = train_test_classifier(rf_clf, X_train, y_train, X_test, y_test, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate XGBoost\n",
    "xgb_clf = train_test_classifier(xgb_clf, X_train, y_train, X_test, y_test, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cross-Validation\n",
    "\n",
    "Let's perform k-fold cross-validation like in the BACE example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Create StratifiedKFold (important for imbalanced datasets)\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validate Random Forest\n",
    "rf_cv_scores = cross_val_score(\n",
    "    rf_clf, X_train, y_train,\n",
    "    cv=skf,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Random Forest Cross-Validation (ROC-AUC):\")\n",
    "print(f\"  Mean: {rf_cv_scores.mean():.3f}\")\n",
    "print(f\"  Std:  {rf_cv_scores.std():.3f}\")\n",
    "print(f\"  Scores: {rf_cv_scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate XGBoost\n",
    "xgb_cv_scores = cross_val_score(\n",
    "    xgb_clf, X_train, y_train,\n",
    "    cv=skf,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"XGBoost Cross-Validation (ROC-AUC):\")\n",
    "print(f\"  Mean: {xgb_cv_scores.mean():.3f}\")\n",
    "print(f\"  Std:  {xgb_cv_scores.std():.3f}\")\n",
    "print(f\"  Scores: {xgb_cv_scores}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Summary\n\nThis notebook demonstrated:\n1. Loading and exploring the SIDER dataset\n2. Canonicalizing SMILES strings with RDKit\n3. Generating MACCS fingerprints using **RDKit directly** (no DeepChem needed!)\n4. Removing zero-variance features\n5. Training Random Forest and XGBoost **classifiers** (vs. regressors in BACE)\n6. Evaluating with classification metrics (Accuracy, F1, ROC-AUC)\n7. Cross-validation with stratified k-folds\n\n**Key Differences from BACE notebook:**\n- BACE uses DeepChem wrapper, this uses RDKit's `MACCSkeys.GenMACCSKeys()` directly\n- Both produce the same 167-bit MACCS fingerprints!\n- This approach avoids TensorFlow dependency (lighter installation)\n\n**Next Steps:**\n- Try predicting other side-effect categories\n- Implement multi-label classification (predict all 27 side effects simultaneously)\n- Try different fingerprints (Morgan, RDKit descriptors)\n- Tune hyperparameters using GridSearchCV"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}